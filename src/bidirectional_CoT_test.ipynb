{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "44aca3b9-657f-4aa6-afd3-7669b39a4d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv.main import load_dotenv\n",
    "import os\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts.chat import (\n",
    "    ChatPromptTemplate,\n",
    "    SystemMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    ")\n",
    "import json\n",
    "from langchain.output_parsers import StructuredOutputParser, ResponseSchema\n",
    "from langchain.chains import LLMChain\n",
    "def output_repraser(input_string):\n",
    "    json_str = input_string.strip('```json\\n').rstrip('\\n```').strip()\n",
    "    \n",
    "    # Step 2: Parse the JSON string into a dictionary\n",
    "    data_dict = json.loads(json_str)\n",
    "    return data_dict\n",
    "\n",
    "class ChatModelWorker:\n",
    "    def __init__(self, output_parser,temperature=0, model='gpt-4'):\n",
    "        with open('api_key.txt','r') as f:\n",
    "            apikey = f.read()\n",
    "        self.chat_model = ChatOpenAI(openai_api_key=apikey, model_name=model, temperature=temperature)\n",
    "        self.output_parser = output_parser\n",
    "\n",
    "    def prompt_temps(self, sys_temp, human_temp, format_instructions):\n",
    "\n",
    "        sys_msg_prompt = SystemMessagePromptTemplate.from_template(sys_temp)\n",
    "        human_msg_prompt = HumanMessagePromptTemplate.from_template(human_temp)\n",
    "        chat_prompt = ChatPromptTemplate(partial_variables={\"format_instructions\": format_instructions},\n",
    "                                         messages=[sys_msg_prompt, human_msg_prompt])\n",
    "        return chat_prompt\n",
    "\n",
    "\n",
    "    def chain_generator(self, template, human_template):\n",
    "        output_parser = self.output_parser\n",
    "        format_instructions = output_parser.get_format_instructions()\n",
    "        chain = LLMChain(\n",
    "            llm=self.chat_model,\n",
    "            prompt=self.prompt_temps(template, human_template, format_instructions)\n",
    "        )\n",
    "        return chain\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adac5e7d-3a4f-4329-97da-e035589899ee",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Direct F-B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "172e761e-e848-4791-a62a-69b88b767821",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class ChatModelWorker:\n",
    "    def __init__(self, output_parser,temperature=0, model='gpt-4'):\n",
    "        with open('api_key.txt','r') as f:\n",
    "            apikey = f.read()\n",
    "        self.chat_model = ChatOpenAI(openai_api_key=apikey, model_name=model, temperature=temperature)\n",
    "        self.output_parser = output_parser\n",
    "\n",
    "    def prompt_temps(self, sys_temp, human_temp, format_instructions):\n",
    "\n",
    "        sys_msg_prompt = SystemMessagePromptTemplate.from_template(sys_temp)\n",
    "        human_msg_prompt = HumanMessagePromptTemplate.from_template(human_temp)\n",
    "        chat_prompt = ChatPromptTemplate(partial_variables={\"format_instructions\": format_instructions},\n",
    "                                         messages=[sys_msg_prompt, human_msg_prompt])\n",
    "        return chat_prompt\n",
    "\n",
    "\n",
    "    def chain_generator(self, template, human_template):\n",
    "        output_parser = self.output_parser\n",
    "        format_instructions = output_parser.get_format_instructions()\n",
    "        chain = LLMChain(\n",
    "            llm=self.chat_model,\n",
    "            prompt=self.prompt_temps(template, human_template, format_instructions)\n",
    "        )\n",
    "        return chain\n",
    "\n",
    "import json\n",
    "\n",
    "def output_repraser(input_string):\n",
    "    json_str = input_string.strip('```json\\n').rstrip('\\n```').strip()\n",
    "    \n",
    "    # Step 2: Parse the JSON string into a dictionary\n",
    "    data_dict = json.loads(json_str)\n",
    "    return data_dict\n",
    "\n",
    "\n",
    "\n",
    "def qa_agent(subject, question, temp=0, model_name='gpt-4-0125-preview'):\n",
    "    system_prompt = (\n",
    "        \"You are a professional specialized in {subject}. You need to help me answer the given question.\"\n",
    "        \"Notice that you need to solve the question step by step. Do not jump to the answer directly.\"\n",
    "        \"Your intermediate steps and thoughts are critical!\"\n",
    "        \"\\n{format_instructions}\")\n",
    "    human_prompt = \"{question}\"\n",
    "        \n",
    "    response_schemas = [\n",
    "        ResponseSchema(name=\"Chain of Thought\",\n",
    "                       description=\"Provide step by step analysis. For instance, you should follow the pattern 'step 1:... \\nstep 2:...'\"),\n",
    "        ResponseSchema(name=\"Backwards Chain of Thought\",\n",
    "                       description=\"Now, you use your obtained answer and performing reverse checking. In other words, you plug in the answer to the steps to verify if each step holds. For instance, you should start from the last step you proposed the pattern 'step n:... \\nstep n-1:...'\"),\n",
    "        ResponseSchema(name=\"Final Answer\",\n",
    "                       description=\"Give me your original answer and your backward analysis answer\")\n",
    "    ]\n",
    "    output_parser = StructuredOutputParser.from_response_schemas(response_schemas)\n",
    "    success = False\n",
    "    while not success:\n",
    "        try:\n",
    "            worker = ChatModelWorker(output_parser=output_parser,temperature=temp, model=model_name)\n",
    "            chain = worker.chain_generator(system_prompt, human_prompt)\n",
    "            out_put = chain.run(subject=subject,\n",
    "                                question=question)\n",
    "\n",
    "            success = True\n",
    "        except:\n",
    "            worker = ChatModelWorker(output_parser=output_parser,temperature=temp, model=model_name)\n",
    "            chain = worker.chain_generator(system_prompt, human_prompt)\n",
    "            out_put = chain.run(subject=subject,\n",
    "                                question=question)\n",
    "    return output_repraser(out_put)\n",
    "\n",
    "def qa_agent_back(subject, question, temp=0, model_name='gpt-4-0125-preview'):\n",
    "    system_prompt = (\n",
    "        \"You are a professional specialized in {subject}. You need to help me answer the given question.\"\n",
    "        \"Notice that you need to solve the question step by step. Do not jump to the answer directly. Do not use latex notations\"\n",
    "        \"Your intermediate steps and thoughts are critical, you should start from the last step to the first step!\" \n",
    "        \"\\n{format_instructions}\")\n",
    "    human_prompt = \"{question}\"\n",
    "        \n",
    "    response_schemas = [\n",
    "        ResponseSchema(name=\"Chain of Thought\",\n",
    "                       description=\"Provide step by step analysis in reverse order. For instance, you should follow the pattern 'step n:... \\nstep n-1:...'\"),\n",
    "        ResponseSchema(name=\"Final Answer\",\n",
    "                       description=\"Give me your original answer and your backward analysis answer\")\n",
    "    ]\n",
    "    output_parser = StructuredOutputParser.from_response_schemas(response_schemas)\n",
    "    success = False\n",
    "    while not success:\n",
    "        try:\n",
    "            worker = ChatModelWorker(output_parser=output_parser,temperature=temp, model=model_name)\n",
    "            chain = worker.chain_generator(system_prompt, human_prompt)\n",
    "            out_put = chain.run(subject=subject,\n",
    "                                question=question)\n",
    "\n",
    "            success = True\n",
    "        except:\n",
    "            worker = ChatModelWorker(output_parser=output_parser,temperature=temp, model=model_name)\n",
    "            chain = worker.chain_generator(system_prompt, human_prompt)\n",
    "            out_put = chain.run(subject=subject,\n",
    "                                question=question)\n",
    "    return (out_put)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b26c5a93b13bf715",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-16T21:49:13.281851800Z",
     "start_time": "2024-02-16T21:48:35.034133Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "subject = 'math'\n",
    "question = '''\n",
    "Suppose that the UW midnight sun solar car team decided, unwisely, to use an undamped\n",
    "suspension system with spring constant k = 1 and dampening constant b = 0. In the absence of\n",
    "a forcing term, a spring with these physical properties and the initial conditions y(0) = 1 and\n",
    "y'(0) = 0 oscillates forever between y = −1 and y = 1. Find\n",
    "a forcing terms so that fap(t) remains bounded while y(t) is unbounded (i.e. there is\n",
    "a real number M (notice that M cannot be +-inf) such that for all t  |fap(t)| < M but limit of y(t) = ±inf when t approaching to inf).\n",
    "You should explicitly compute what your fap(t) functions are.'''\n",
    "result = qa_agent(subject=subject,question=question)\n",
    "print(result['Chain of Thought'])\n",
    "print('-------------------------------------------')\n",
    "print(result['Backwards Chain of Thought'])\n",
    "print('-------------------------------------------')\n",
    "print(result['Final Answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a7b8e72e3824cfb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-16T22:09:51.864175Z",
     "start_time": "2024-02-16T22:09:23.814667600Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "subject = 'math'\n",
    "question = '''\n",
    "Suppose that the UW midnight sun solar car team decided, unwisely, to use an undamped\n",
    "suspension system with spring constant k = 1 and dampening constant b = 0. In the absence of\n",
    "a forcing term, a spring with these physical properties and the initial conditions y(0) = 1 and\n",
    "y'(0) = 0 oscillates forever between y = −1 and y = 1. Find\n",
    "a forcing terms so that fap(t) remains bounded while y(t) is unbounded (i.e. there is\n",
    "a real number M (notice that M cannot be +-inf) such that for all t  |fap(t)| < M but limit of y(t) = ±inf when t approaching to inf).\n",
    "You should explicitly compute what your fap(t) functions are.'''\n",
    "result = qa_agent_back(subject=subject,question=question)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4964679f4d370b0f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-16T22:13:18.808856900Z",
     "start_time": "2024-02-16T22:13:18.797527700Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7188286a8a12dde8",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# Verify Chain steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "13c5a9a46cd5ea1e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-19T16:48:34.302502100Z",
     "start_time": "2024-02-19T16:48:34.287871500Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def forward_agent(subject, question, temp=0, model_name='gpt-4-0125-preview'):\n",
    "    system_prompt = (\n",
    "        \"You are a professional specialized in {subject}. You need to help me answer the given question.\"\n",
    "        \"Notice that you need to solve the question step by step. Do not jump to the answer directly.\"\n",
    "        \"Your intermediate steps and thoughts are critical!\"\n",
    "        \"\\n{format_instructions}\")\n",
    "    human_prompt = \"{question}\"\n",
    "        \n",
    "    response_schemas = [\n",
    "        ResponseSchema(name=\"Chain of Thought\",\n",
    "                       description=\"Provide step by step analysis. For instance, you should follow the pattern 'step 1:... \\nstep 2:...'\"),\n",
    "        ResponseSchema(name=\"Number of Steps Proposed\",\n",
    "                       description=\"return a simple integer output which indicates the number of steps you proposed in the Chain of Thought\"),\n",
    "        ResponseSchema(name=\"Final Answer\",\n",
    "                       description=\"Give me your final answer\")\n",
    "    ]\n",
    "    output_parser = StructuredOutputParser.from_response_schemas(response_schemas)\n",
    "    success = False\n",
    "    while not success:\n",
    "        try:\n",
    "            worker = ChatModelWorker(output_parser=output_parser,temperature=temp, model=model_name)\n",
    "            chain = worker.chain_generator(system_prompt, human_prompt)\n",
    "            out_put = chain.run(subject=subject,\n",
    "                                question=question)\n",
    "\n",
    "            success = True\n",
    "        except:\n",
    "            worker = ChatModelWorker(output_parser=output_parser,temperature=temp, model=model_name)\n",
    "            chain = worker.chain_generator(system_prompt, human_prompt)\n",
    "            out_put = chain.run(subject=subject,\n",
    "                                question=question)\n",
    "    return out_put\n",
    "def back_check_agent(subject, current_step,cot,final_answer, temp=0, model_name='gpt-4-0125-preview'):\n",
    "    system_prompt = (\n",
    "        '''You are a professional specialized in {subject}. You need to help me verify my steps when I solve the question.\n",
    "        Your goal is help me first verify that given the final answer as {final_answer} and I am currently at step #{current_step},\n",
    "        is the current step correct?. If it is correct, then verify that will my current step make the previous step hold? In other words, \n",
    "        check the logic consistency of step n and step n-1 where n is my current step. It is important that for each analysis, ignore steps\n",
    "        other than the current step and the previous step!\n",
    "        \\n{format_instructions}\n",
    "''')\n",
    "    human_prompt = \"Here is my complete thought process {cot}\"\n",
    "        \n",
    "    response_schemas = [\n",
    "        ResponseSchema(name=\"Verification\",\n",
    "                       description=\"Help me verify the correctness of the current step and the logic consistency, and tell me the reason\"),\n",
    "        ResponseSchema(name=\"Step Correctness\",\n",
    "                       description=\"say [YES] if correct, otherwise [NO]\"),\n",
    "        ResponseSchema(name=\"Logic Consistency\",\n",
    "                       description=\"say [YES] if consistent, otherwise [NO]\")\n",
    "    ]\n",
    "    output_parser = StructuredOutputParser.from_response_schemas(response_schemas)\n",
    "    success = False\n",
    "    while not success:\n",
    "        try:\n",
    "            worker = ChatModelWorker(output_parser=output_parser,temperature=temp, model=model_name)\n",
    "            chain = worker.chain_generator(system_prompt, human_prompt)\n",
    "            out_put = chain.run(subject=subject,\n",
    "                                current_step=current_step,cot=cot,final_answer=final_answer)\n",
    "\n",
    "            success = True\n",
    "        except:\n",
    "            worker = ChatModelWorker(output_parser=output_parser,temperature=temp, model=model_name)\n",
    "            chain = worker.chain_generator(system_prompt, human_prompt)\n",
    "            out_put = chain.run(subject=subject,\n",
    "                                current_step=current_step,cot=cot,final_answer=final_answer)\n",
    "    return out_put"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "535f7b795f2b408c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-19T16:16:18.995509100Z",
     "start_time": "2024-02-19T16:15:55.156230Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# subject = 'math'\n",
    "# question = '''\n",
    "# Solve for x: x^2+10x+24=0\n",
    "# '''\n",
    "# result = forward_agent(subject=subject, question=question)\n",
    "# result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1b3a75c8164101a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-19T16:17:24.416420900Z",
     "start_time": "2024-02-19T16:17:24.401191700Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# forward_result = output_repraser(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b76af207f8ea7ffa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-19T16:27:06.573308900Z",
     "start_time": "2024-02-19T16:27:06.560044Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# cot,steps,final_answer = forward_result.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54ff260e8954d1fa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-19T16:27:29.620816200Z",
     "start_time": "2024-02-19T16:27:29.604641300Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# current_step = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57d871b1fef17f59",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-19T16:29:44.233851200Z",
     "start_time": "2024-02-19T16:29:38.592773Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# back_check_result = back_check_agent(subject=subject,current_step=current_step,cot=cot,final_answer=final_answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1b1d5296a74546c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-19T16:29:50.130971200Z",
     "start_time": "2024-02-19T16:29:50.118476900Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# output_repraser(back_check_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e21ca04e41b99b96",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-19T16:32:06.112728900Z",
     "start_time": "2024-02-19T16:31:25.188890800Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# check_list = []\n",
    "# for i in range(7):\n",
    "#     current_step = 7-i\n",
    "#     back_check_result = back_check_agent(subject=subject,current_step=current_step,cot=cot,final_answer=final_answer)\n",
    "#     response = output_repraser(back_check_result)\n",
    "#     print(response)\n",
    "#     check_list.append(response['Final Answer'])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8a6344d5bf10b9e4",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-02-19T16:50:42.382822100Z"
    },
    "collapsed": false,
    "is_executing": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Chain of Thought': \"step 1: Identify the differential equation type. The given equation is a second-order linear homogeneous differential equation of the form y'' + p(x)y' + q(x)y = 0, where p(x) = 1 and q(x) = -2.\\nstep 2: Solve the characteristic equation associated with the differential equation. The characteristic equation is r^2 + r - 2 = 0.\\nstep 3: Factor the characteristic equation. It factors to (r + 2)(r - 1) = 0, giving us roots r1 = -2 and r2 = 1.\\nstep 4: Write the general solution to the differential equation using the roots from the characteristic equation. Since the roots are real and distinct, the general solution is y(x) = C1*e^(r1*x) + C2*e^(r2*x) = C1*e^(-2x) + C2*e^(x).\\nstep 5: Apply the initial condition y(0) = 1. Plugging in x = 0, we get 1 = C1*e^(0) + C2*e^(0) = C1 + C2. So, C1 + C2 = 1.\\nstep 6: Apply the condition y -> 0 as x -> inf. For y to approach 0 as x approaches infinity, the term involving e^(x) must have a coefficient of 0 because e^(x) grows without bound. Therefore, C2 must be 0.\\nstep 7: Solve for C1 using the equation from step 5 with C2 = 0. We get C1 = 1.\\nstep 8: Write the final solution using the values of C1 and C2. Since C1 = 1 and C2 = 0, the solution is y(x) = e^(-2x).\", 'Number of Steps Proposed': '8', 'Final Answer': 'y(x) = e^(-2x)'}\n",
      "------------------------------------------------------\n",
      "Step 8 {'Verification': 'The current step correctly identifies the final solution based on the values of C1 and C2 obtained in the previous steps. Given C1 = 1 and C2 = 0, the final solution y(x) = e^(-2x) is correctly derived.', 'Step Correctness': 'YES', 'Logic Consistency': 'YES'} \n",
      "\n",
      "\n",
      "Step 7 {'Verification': 'The current step is correct and logically consistent with the previous step.', 'Step Correctness': 'YES', 'Logic Consistency': 'YES'} \n",
      "\n",
      "\n",
      "Step 6 {'Verification': 'The current step is correct and the logic is consistent with the previous step. In step 6, the condition that y approaches 0 as x approaches infinity correctly leads to the conclusion that C2 must be 0, because the term e^(x) would otherwise grow without bound, making it impossible for y to approach 0. This reasoning directly follows from the general solution found in step 4 and the initial condition applied in step 5.', 'Step Correctness': 'YES', 'Logic Consistency': 'YES'} \n",
      "\n",
      "\n",
      "Step 5 {'Verification': 'The current step is correct and logically consistent with the previous step. In step 5, the initial condition y(0) = 1 was correctly applied to the general solution, resulting in the equation C1 + C2 = 1. This step is a necessary precursor to determining the specific values of C1 and C2, which are needed to find the particular solution to the differential equation.', 'Step Correctness': 'YES', 'Logic Consistency': 'YES'} \n",
      "\n",
      "\n",
      "Step 4 {'Verification': 'The current step correctly identifies the final solution based on the values of C1 and C2 obtained in the previous steps. Given C1 = 1 and C2 = 0, the final solution y(x) = e^(-2x) is correctly derived from the general solution.', 'Step Correctness': 'YES', 'Logic Consistency': 'YES'} \n",
      "\n",
      "\n",
      "Step 3 {'Verification': 'The current step correctly factors the characteristic equation based on the roots provided. However, the roots derived from the characteristic equation in step 2 (r^2 + r - 2 = 0) should be r1 = 1 and r2 = -2, not r1 = -2 and r2 = 1 as stated. The correct factoring of the characteristic equation is indeed (r + 2)(r - 1) = 0, but the interpretation of the roots seems to have been mistakenly swapped in the explanation.', 'Step Correctness': 'NO', 'Logic Consistency': 'NO'} \n",
      "\n",
      "\n",
      "Step 2 {'Verification': \"The current step (step 2) of solving the characteristic equation r^2 + r - 2 = 0 is correct and logically consistent with the identification of the differential equation type in step 1. The form of the differential equation y'' + p(x)y' + q(x)y = 0, with p(x) = 1 and q(x) = -2, correctly leads to the characteristic equation r^2 + r - 2 = 0 when solving second-order linear homogeneous differential equations.\", 'Step Correctness': 'YES', 'Logic Consistency': 'YES'} \n",
      "\n",
      "\n",
      "Step 1 {'Verification': 'The current step is correct and the logic consistency between the current step and the previous step holds. The final solution y(x) = e^(-2x) is correctly derived by applying the initial conditions and the behavior of the solution as x approaches infinity to determine the constants C1 and C2.', 'Step Correctness': 'YES', 'Logic Consistency': 'YES'} \n",
      "\n",
      "\n",
      "------------------------------------------------------\n",
      "[('YES', 'YES'), ('YES', 'YES'), ('YES', 'YES'), ('YES', 'YES'), ('YES', 'YES'), ('NO', 'NO'), ('YES', 'YES'), ('YES', 'YES')]\n"
     ]
    }
   ],
   "source": [
    "subject = 'math'\n",
    "question = '''\n",
    "Solve for y(x): y''+y'-2y=0. y(0)=1, y->0 as x-> inf\n",
    "'''\n",
    "result = forward_agent(subject=subject, question=question)\n",
    "forward_result = output_repraser(result)\n",
    "print(forward_result)\n",
    "print('------------------------------------------------------')\n",
    "cot,steps,final_answer = forward_result.values()\n",
    "check_list = []\n",
    "for i in range(int(steps)):\n",
    "    current_step = int(steps)-i\n",
    "    back_check_result = back_check_agent(subject=subject,current_step=current_step,cot=cot,final_answer=final_answer)\n",
    "    response = output_repraser(back_check_result)\n",
    "    print(f'Step {current_step}',response,'\\n\\n')\n",
    "    check_list.append((response['Step Correctness'],response['Logic Consistency']))\n",
    "print('------------------------------------------------------')\n",
    "print(check_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70e7df1645b124cc",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_hall",
   "language": "python",
   "name": "llm_hall_project"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
